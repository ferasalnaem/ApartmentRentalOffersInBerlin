{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# To add a new cell, type '# %%'\n",
        "# To add a new markdown cell, type '# %% [markdown]'\n",
        "# %%\n",
        "from IPython import get_ipython\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": []
      },
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# To plot pretty figures\n",
        "get_ipython().run_line_magic('matplotlib', 'inline')\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Ignore useless warnings (see SciPy issue #5998)\n",
        "import warnings\n",
        "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing\n",
        "import matplotlib.pyplot as plt # dataviz\n",
        "import seaborn as sns # dataviz\n",
        "from pandas.plotting import scatter_matrix\n",
        "\n",
        "Rental= pd.read_csv(\"./dataset/immo_data.csv\")\n",
        "\n",
        "get_ipython().run_line_magic('matplotlib', 'inline')\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "Rental.info()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "Rental.describe() #shows a summary of the numerical attributes\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": []
      },
      "source": [
        "Berlin=Rental.loc[Rental[\"regio2\"]=='Berlin']\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Berlin.shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "corr_matrix = Berlin.corr()\n",
        "corr_matrix[\"totalRent\"].sort_values(ascending=False)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "attributes = [\"baseRent\",\"totalRent\",\"livingSpace\", \"serviceCharge\", \"noRooms\",\"heatingCosts\",\"picturecount\"]\n",
        "scatter_matrix(Berlin[attributes], figsize=(16, 12))\n",
        "scatter_matrix\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "Berlin[\"totalRent\"].describe()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "Berlin['totalRent'].hist(bins=30, range=(100,4000), grid=True, color='#86bf91')\n",
        "plt.title('Distribution of Base Rents')\n",
        "plt.xlabel('Total Rent')\n",
        "plt.ylabel('Count')\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "Berlin.plot(kind=\"scatter\", x=\"livingSpace\", y=\"totalRent\", alpha=0.1)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Berlin.plot(kind=\"scatter\", x=\"yearConstructed\", y=\"totalRent\", alpha=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "m=Berlin.groupby(['regio3'])['baseRent'].mean()\n",
        "m.sort_values()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#droping initial columns\n",
        "cols_to_drop = [\"telekomHybridUploadSpeed\", \"picturecount\", \"telekomUploadSpeed\",\n",
        "                \"geo_bln\", \"houseNumber\", \"geo_krs\", \"geo_plz\", \"regio3\", \"description\",\n",
        "                \"facilities\"]\n",
        "\n",
        "Berlin = Berlin.drop(cols_to_drop, axis=1)\n",
        "\n",
        "#Columns with several NULL entries are dropped too.\n",
        "\n",
        "Berlin.isna().sum()\n",
        "\n",
        "#filter columns for berlin\n",
        "Berlin = Berlin[Berlin[\"regio2\"]==\"Berlin\"]\n",
        "\n",
        "#sorting and re_indexing regarding to the price\n",
        "Berlin = Berlin.sort_values(by=['totalRent'])\n",
        "Berlin = Berlin.reset_index(drop=True)\n",
        "\n",
        "#filter some columns between specific amount of values\n",
        "Berlin = Berlin.query(\"totalRent >= 100\").query(\"totalRent<10000\")\n",
        "Berlin = Berlin.query(\"baseRent >= 100\").query(\"baseRent<10000\")\n",
        "Berlin = Berlin.query(\"livingSpace >= 10\").query(\"livingSpace<400\")\n",
        "Berlin = Berlin.query(\"noRooms >= 0\").query(\"noRooms<15\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Replacing columns with f/t with 0/1\n",
        "Berlin.replace({False: 0, True: 1}, inplace=True)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#make a single binary variable to indicate if the apartment is refurbished/new\n",
        "Berlin['refurbished'] = (Berlin.condition == 'refurbished') | (Berlin.condition == 'first_time_use') | (Berlin.condition == 'mint_condition') | (Berlin.condition == 'fully_renovated') | (Berlin.condition == 'first_time_use_after_refurbishment')\n",
        "\n",
        "#make a binary variable to indicate if the rental property has good interior\n",
        "Berlin['greatInterior'] = (Berlin.interiorQual == 'sophisticated') | (Berlin.interiorQual == 'luxury')\n",
        "\n",
        "#make a binary variable to indicated if the rental property has good heating\n",
        "Berlin['goodHeating'] = (Berlin.heatingType == 'central_heating') | (Berlin.heatingType == 'floor_heating') | (Berlin.heatingType == 'self_contained_central_heating')\n",
        "\n",
        "#make a binary variable to identify rental ads from last year to factor in any inflationary effects.\n",
        "Berlin['2018_ads'] = (Berlin.date == 'Sep18')\n",
        "\n",
        "#transform totalRent into log(totalRent) to get a better distribution + better interpretive quality\n",
        "Berlin['logRent'] = np.log(Berlin['totalRent'])\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": []
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
        "\n",
        "y_var = ['logRent']\n",
        "X_var = ['balcony', 'hasKitchen', 'cellar', 'livingSpace', 'noRooms', 'garden', \n",
        "         'refurbished', 'greatInterior', 'newlyConst',\n",
        "         '2018_ads', 'lift']\n",
        "\n",
        "#print(Berlin[X_var])\n",
        "\n",
        "y = Berlin[y_var].iloc[:,0].values\n",
        "X = Berlin[X_var].iloc[:,3].values\n",
        "#y = Berlin[y_var].values\n",
        "#X = Berlin[X_var].values\n",
        "\n",
        "#print(X)\n",
        "#print(y)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, \n",
        "                                                    random_state=0)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fine tunning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Linear Regression model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "linear_regressor = LinearRegression()\n",
        "#linear_regressor.fit(np.array(X_train.reshape(-1, 1)), y_train.reshape(-1, 1))\n",
        "linear_regressor.fit(X_train.reshape(-1, 1), y_train.reshape(-1, 1))\n",
        "                     \n",
        "\n",
        "y_predict = linear_regressor.predict(X_train.reshape(-1, 1))\n",
        "print(y_predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot points and fit line for training data\n",
        "plt.scatter(X_train.reshape(-1, 1), y_train.reshape(-1, 1), color='teal', edgecolors='black', label='Training-set observation points')\n",
        "plt.plot(X_train, y_predict, color='grey', label='Fit Regression Line')\n",
        "plt.title('totalRent vs features')\n",
        "plt.xlabel('features')\n",
        "plt.ylabel('totalRent (in USD)')\n",
        "\n",
        "# plot scatter points and line for test data\n",
        "plt.scatter(X_test, y_test, color='red', edgecolors='black', label='Test-set observation points')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Decision Tree model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "tree_reg = DecisionTreeRegressor()\n",
        "tree_reg.fit(X_train.reshape(-1, 1), y_train.reshape(-1, 1))\n",
        "tree_scores = cross_val_score(tree_reg, X_train.reshape(-1, 1), y_train.reshape(-1, 1),\n",
        "                              scoring=\"neg_mean_squared_error\", cv=10)\n",
        "tree_rmse_scores = np.sqrt(-tree_scores)\n",
        "tree_rmse_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "def display_scores(scores):\n",
        "    print(\"Scores:\", scores)\n",
        "    print(\"Mean:\", scores.mean())\n",
        "    print(\"Standard deviation:\", scores.std())\n",
        "\n",
        "display_scores(tree_rmse_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lin_scores = cross_val_score(tree_reg, X_test.reshape(-1, 1), y_test.reshape(-1, 1),\n",
        "                             scoring=\"neg_mean_squared_error\", cv=10)\n",
        "lin_rmse_scores = np.sqrt(-lin_scores)\n",
        "display_scores(lin_rmse_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Random forest model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "y_var = ['logRent']\n",
        "X_var = ['balcony', 'hasKitchen', 'cellar', 'livingSpace', 'noRooms', 'garden', 'baseRent',\n",
        "         'refurbished', 'greatInterior', 'newlyConst',\n",
        "         '2018_ads', 'lift']\n",
        "\n",
        "#print(Berlin[X_var])\n",
        "#y = Berlin[y_var].iloc[:,0].values\n",
        "#X = Berlin[X_var].iloc[:,0].values\n",
        "y = Berlin[y_var].values\n",
        "X = Berlin[X_var].values\n",
        "\n",
        "print(X)\n",
        "#print(y)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, \n",
        "                                                    random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "forest_reg = RandomForestRegressor()\n",
        "forest_reg.fit(X_train, y_train)\n",
        "prediction = forest_reg.predict(X_test)\n",
        "forest_mse21 = mean_squared_error(y_test, prediction)\n",
        "forest_rmse21 = np.sqrt(forest_mse21)\n",
        "print(\"rmse:\", forest_rmse21)\n",
        "print(\"mse:\", forest_mse21)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "forest_scores = cross_val_score(forest_reg, X_test, y_test,\n",
        "                                scoring=\"neg_mean_squared_error\", cv=10)\n",
        "forest_rmse_scores = np.sqrt(-forest_scores)\n",
        "display_scores(forest_rmse_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "scores = cross_val_score(forest_reg, X_test, y_test, scoring=\"neg_mean_squared_error\", cv=10)\n",
        "pd.Series(np.sqrt(-scores)).describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fine tunning Random forest Regressor(Grid Search)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = [\n",
        "        {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 11]},\n",
        "        {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
        "    ]\n",
        "\n",
        "forest_reg = RandomForestRegressor()\n",
        "grid_search = GridSearchCV(forest_reg, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "grid_search.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "grid_search.best_params_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "grid_search.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "cvres = grid_search.cv_results_\n",
        "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
        "    print(np.sqrt(-mean_score), params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### fine tunning Random forest regressor(RandomizedSearch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint\n",
        "\n",
        "param_distribs = {\n",
        "        'n_estimators': randint(low=1, high=200),\n",
        "        'max_features': randint(low=1, high=8),\n",
        "    }\n",
        "\n",
        "forest_reg1 = RandomForestRegressor()\n",
        "rnd_search = RandomizedSearchCV(forest_reg1, param_distributions=param_distribs,\n",
        "                                n_iter=10, cv=5, scoring='neg_mean_squared_error')\n",
        "rnd_search.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rnd_search.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rnd_search.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "cvres = rnd_search.cv_results_\n",
        "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
        "    print(np.sqrt(-mean_score), params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_importances = rnd_search.best_estimator_.feature_importances_\n",
        "feature_importances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "final_model = grid_search.best_estimator_\n",
        "\n",
        "#X_test = strat_test_set.drop(\"median_house_value\", axis=1)\n",
        "#y_test = strat_test_set[\"median_house_value\"].copy()\n",
        "\n",
        "#X_test_transformed = preparation_pipeline.transform(X_test)\n",
        "final_predictions = final_model.predict(X_test)\n",
        "\n",
        "final_mse0 = mean_squared_error(y_test, final_predictions)\n",
        "final_rmse0 = np.sqrt(final_mse0)\n",
        "print(\"rmse:\", final_rmse0)\n",
        "print(\"mse:\", final_mse0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
        "\n",
        "y_var = ['logRent']\n",
        "X_var = ['balcony', 'hasKitchen', 'cellar', 'livingSpace', 'noRooms', 'garden', \n",
        "         'refurbished', 'greatInterior', 'newlyConst',\n",
        "         '2018_ads', 'lift']\n",
        "\n",
        "#print(Berlin[X_var])\n",
        "\n",
        "y = Berlin[y_var].iloc[:,0].values\n",
        "X = Berlin[X_var].iloc[:,3:4].values\n",
        "#y = Berlin[y_var].values\n",
        "#X = Berlin[X_var].values\n",
        "\n",
        "#print(X)\n",
        "#print(y)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, \n",
        "                                                    random_state=0)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
        "\n",
        "y_var = ['logRent']\n",
        "X_var = ['balcony', 'hasKitchen', 'cellar', 'livingSpace', 'noRooms', 'garden', \n",
        "         'refurbished', 'greatInterior', 'newlyConst',\n",
        "         '2018_ads', 'lift']\n",
        "\n",
        "#print(Berlin[X_var])\n",
        "\n",
        "y = Berlin[y_var].iloc[:,0].values\n",
        "…\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\"\"\"forest_regressor = RandomForestRegressor(n_estimators = 30, random_state = 1111,\n",
        "                                         max_depth=30, max_features=6, min_samples_leaf=10)\"\"\"\n",
        "\n",
        "forest_regressor = RandomForestRegressor(n_estimators = 30, random_state = 42)\n",
        "forest_regressor.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "X_grid = np.arange(min(X), max(X), 0.01)\n",
        "X_grid = X_grid.reshape(len(X_grid), 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Plot points and fit line for training data\n",
        "plt.scatter(X_train, y_train, color='teal', edgecolors='black', label='Training-set observation points')\n",
        "plt.plot(X_grid, forest_regressor.predict(X_grid), color='grey', label='Random Regressor Line')\n",
        "plt.title('totalRent vs features')\n",
        "plt.xlabel('features')\n",
        "plt.ylabel('totalRent (in USD)')\n",
        "\n",
        "# plot scatter points and line for test data\n",
        "plt.scatter(X_test, y_test, color='red', edgecolors='black', label='Test-set observation points')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. GradientBoosting "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "y_var = ['logRent']\n",
        "X_var = ['balcony', 'hasKitchen', 'cellar', 'livingSpace', 'noRooms', 'garden',\n",
        "         'refurbished', 'greatInterior', 'newlyConst',\n",
        "         '2018_ads', 'lift']\n",
        "\n",
        "#print(Berlin[X_var])\n",
        "#y = Berlin[y_var].iloc[:,0].values\n",
        "#X = Berlin[X_var].iloc[:,0].values\n",
        "y = Berlin[y_var].values\n",
        "X = Berlin[X_var].values\n",
        "\n",
        "print(X)\n",
        "#print(y)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, \n",
        "                                                    random_state=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "\n",
        "gradient_reg = GradientBoostingRegressor()\n",
        "gradient_reg.fit(X_train, y_train)\n",
        "\n",
        "gradient_scores = cross_val_score(gradient_reg, X_train, y_train,\n",
        "                              scoring=\"neg_mean_squared_error\", cv=10)\n",
        "gradient_rmse_scores = np.sqrt(-gradient_scores)\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"gradient_scores = cross_val_score(gradient_reg, X_train, y_train,\n",
        "                             scoring=\"neg_mean_squared_error\", cv=10)\n",
        "gradient_rmse_scores = np.sqrt(-gradient_scores)\n",
        "display_scores(gradient_rmse_scores)\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "grad_reg = GradientBoostingRegressor()\n",
        "grad_reg.fit(X_train, y_train)\n",
        "housing_predictions = grad_reg.predict(X_train)\n",
        "grad_mse12 = mean_squared_error(y_train, housing_predictions)\n",
        "grad_rmse12 = np.sqrt(grad_mse12)\n",
        "print(\"final_rmse:\", grad_rmse12)\n",
        "print(\"final_mse:\", grad_mse12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "grad_scores = cross_val_score(grad_reg, X_train, y_train,\n",
        "                                scoring=\"neg_mean_squared_error\", cv=10)\n",
        "grad_rmse_scores = np.sqrt(-grad_scores)\n",
        "display_scores(grad_rmse_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scores = cross_val_score(grad_reg, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=10)\n",
        "pd.Series(np.sqrt(-scores)).describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### fine tunning gradientBoosting(Gridsearch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "param_grid = [\n",
        "        {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 11]},\n",
        "        {'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
        "    ]\n",
        "\n",
        "gradientBoosting_reg = GradientBoostingRegressor()\n",
        "\n",
        "gradientBoosting_search = GridSearchCV(gradientBoosting_reg, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "gradientBoosting_search.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gradientBoosting_search.best_params_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gradientBoosting_search.best_estimator_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "cvres = gradientBoosting_search.cv_results_\n",
        "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
        "    print(np.sqrt(-mean_score), params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### fine tunning GradientBoosting (RandomizedSearch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint\n",
        "\n",
        "param_distribs = {\n",
        "        'n_estimators': randint(low=1, high=200),\n",
        "        'max_features': randint(low=1, high=8),\n",
        "    }\n",
        "\n",
        "gradientBoost_reg1 = GradientBoostingRegressor()\n",
        "gradientBoost_search = RandomizedSearchCV(gradientBoost_reg1, param_distributions=param_distribs,\n",
        "                                n_iter=10, cv=5, scoring='neg_mean_squared_error')\n",
        "gradientBoost_search.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gradientBoost_search.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gradientBoost_search.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "cvres = gradientBoost_search.cv_results_\n",
        "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
        "    print(np.sqrt(-mean_score), params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_boost_importances = gradientBoost_search.best_estimator_.feature_importances_\n",
        "feature_boost_importances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "final_model1 = gradientBoosting_search.best_estimator_\n",
        "#X_test = strat_test_set.drop(\"median_house_value\", axis=1)\n",
        "#y_test = strat_test_set[\"median_house_value\"].copy()\n",
        "\n",
        "#X_test_transformed = preparation_pipeline.transform(X_test)\n",
        "final_predictions = final_model1.predict(X_test)\n",
        "\n",
        "final_mse2 = mean_squared_error(y_test, final_predictions)\n",
        "final_rmse2 = np.sqrt(final_mse2)\n",
        "print(\"final_rmse:\", final_rmse2)\n",
        "print(\"final_mse:\", final_mse2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
        "\n",
        "y_var = ['logRent']\n",
        "X_var = ['balcony', 'hasKitchen', 'cellar', 'livingSpace', 'noRooms', 'garden', \n",
        "         'refurbished', 'greatInterior', 'newlyConst',\n",
        "         '2018_ads', 'lift']\n",
        "\n",
        "#print(Berlin[X_var])\n",
        "\n",
        "y = Berlin[y_var].iloc[:,0].values\n",
        "X = Berlin[X_var].iloc[:,3].values\n",
        "#y = Berlin[y_var].values\n",
        "#X = Berlin[X_var].values\n",
        "\n",
        "#print(X)\n",
        "#print(y)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, \n",
        "                                                    random_state=0)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\"\"\"forest_regressor = RandomForestRegressor(n_estimators = 30, random_state = 1111,\n",
        "                                         max_depth=30, max_features=6, min_samples_leaf=10)\"\"\"\n",
        "\n",
        "gradient_regressor = GradientBoostingRegressor(n_estimators = 30, random_state =0)\n",
        "gradient_regressor.fit(X_train.reshape(-1, 1), y_train.reshape(-1, 1))\n",
        "\n",
        "\n",
        "X_grid = np.arange(min(X), max(X), 0.01)\n",
        "X_grid = X_grid.reshape(len(X_grid), 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.scatter(X_train, y_train, color='blue', label='Actual observation points')\n",
        "plt.plot(X_grid, gradient_regressor.predict(X_grid), label='Gradient regressor')\n",
        "plt.title('totalRent vs features (Gradient Boosting)')\n",
        "plt.xlabel('features')\n",
        "plt.ylabel('totalRent')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Models ----------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
        "\n",
        "y_var = ['logRent']\n",
        "X_var = ['balcony', 'hasKitchen', 'cellar', 'livingSpace', 'noRooms', 'garden', \n",
        "         'refurbished', 'greatInterior', 'newlyConst',\n",
        "         '2018_ads', 'lift']\n",
        "\n",
        "#print(Berlin[X_var])\n",
        "\n",
        "y = Berlin[y_var].iloc[:,0].values\n",
        "X = Berlin[X_var].iloc[:,3].values\n",
        "#y = Berlin[y_var].values\n",
        "#X = Berlin[X_var].values\n",
        "\n",
        "#print(X)\n",
        "#print(y)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, \n",
        "                                                    random_state=0)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": []
      },
      "source": [
        "#LINEAR REGRESSION\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import metrics\n",
        "\n",
        "def linear__regression(xtrain, ytrain, xtest, ytest):\n",
        "    linreg = LinearRegression()\n",
        "    linreg.fit(xtrain, ytrain)\n",
        "    y_pred = linreg.predict(xtest)\n",
        "    \n",
        "    print('MAE:', metrics.mean_absolute_error(ytest, y_pred))\n",
        "    print('MSE:', metrics.mean_squared_error(ytest, y_pred))\n",
        "\n",
        "linear__regression(X_train.reshape(-1, 1), y_train.reshape(-1, 1),\n",
        "                 X_test.reshape(-1, 1), y_test.reshape(-1, 1))\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "linear_regressor = LinearRegression()\n",
        "#linear_regressor.fit(np.array(X_train.reshape(-1, 1)), y_train.reshape(-1, 1))\n",
        "linear_regressor.fit(X_train.reshape(-1,1), y_train.reshape(-1,1))\n",
        "                     \n",
        "\n",
        "y_predict = linear_regressor.predict(X_train.reshape(-1,1))\n",
        "print(y_predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Plot points and fit line for training data\n",
        "plt.scatter(X_train, y_train, color='teal', edgecolors='black', label='Training-set observation points')\n",
        "plt.plot(X_train, y_predict, color='grey', label='Fit Regression Line')\n",
        "plt.title('totalRent vs Ex_features')\n",
        "plt.xlabel('Ex_features')\n",
        "plt.ylabel('totalRent (in USD)')\n",
        "\n",
        "# plot scatter points and line for test data\n",
        "plt.scatter(X_test, y_test, color='red', edgecolors='black', label='Test-set observation points')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
        "\n",
        "y_var = ['logRent']\n",
        "X_var = ['balcony', 'hasKitchen', 'cellar', 'livingSpace', 'noRooms', 'garden', \n",
        "         'refurbished', 'greatInterior', 'newlyConst',\n",
        "         '2018_ads', 'lift']\n",
        "\n",
        "#print(Berlin[X_var])\n",
        "\n",
        "y = Berlin[y_var].iloc[:,0].values\n",
        "X = Berlin[X_var].iloc[:,3:4].values\n",
        "#y = Berlin[y_var].values\n",
        "#X = Berlin[X_var].values\n",
        "\n",
        "#print(X)\n",
        "#print(y)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, \n",
        "                                                    random_state=0)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": []
      },
      "source": [
        "\n",
        "#RANDOM FOREST\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "def randomforestreg(msl, mf, md, xtrain, ytrain, xtest, ytest):\n",
        "    rfr_best = RandomForestRegressor(n_estimators=70, random_state=1111,\n",
        "                                     max_depth=md, max_features=mf, min_samples_leaf=msl)\n",
        "    rfr_best.fit(xtrain,ytrain)\n",
        "    y_pred_rfr = rfr_best.predict(xtrain)\n",
        "    print('MAE:', metrics.mean_absolute_error(ytest, y_pred_rfr))\n",
        "    print('MSE:', metrics.mean_squared_error(ytest, y_pred_rfr))\n",
        "    return y_pred_rfr\n",
        "#forest_regressor = randomforestreg(10, 6, 30, X_train, y_train, X_test, y_test)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"from sklearn.svm import SVR\n",
        "\n",
        "scale_X = StandardScaler()\n",
        "scale_y = StandardScaler()\n",
        "\n",
        "X = scale_X.fit_transform(X.reshape(-1,1))\n",
        "y = scale_y.fit_transform(y.reshape(-1,1))\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\"\"\"forest_regressor = RandomForestRegressor(n_estimators = 30, random_state = 1111,\n",
        "                                         max_depth=30, max_features=6, min_samples_leaf=10)\"\"\"\n",
        "\n",
        "forest_regressor = RandomForestRegressor(n_estimators = 30, random_state = 42)\n",
        "forest_regressor.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "X_grid = np.arange(min(X), max(X), 0.01)\n",
        "X_grid = X_grid.reshape(len(X_grid), 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "\n",
        "# Plot points and fit line for training data\n",
        "plt.scatter(X_train, y_train, color='teal', edgecolors='black', label='Training-set observation points')\n",
        "plt.plot(X_grid, forest_regressor.predict(X_grid), color='grey', label='Random Regressor Line')\n",
        "plt.title('totalRent vs features')\n",
        "plt.xlabel('features')\n",
        "plt.ylabel('totalRent (in USD)')\n",
        "\n",
        "# plot scatter points and line for test data\n",
        "plt.scatter(X_test, y_test, color='red', edgecolors='black', label='Test-set observation points')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
        "\n",
        "y_var = ['logRent']\n",
        "X_var = ['balcony', 'hasKitchen', 'cellar', 'livingSpace', 'noRooms', 'garden', \n",
        "         'refurbished', 'greatInterior', 'newlyConst',\n",
        "         '2018_ads', 'lift']\n",
        "\n",
        "#print(Berlin[X_var])\n",
        "\n",
        "y = Berlin[y_var].iloc[:,0].values\n",
        "X = Berlin[X_var].iloc[:,3].values\n",
        "#y = Berlin[y_var].values\n",
        "#X = Berlin[X_var].values\n",
        "\n",
        "#print(X)\n",
        "#print(y)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, \n",
        "                                                    random_state=0)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\"\"\"forest_regressor = RandomForestRegressor(n_estimators = 30, random_state = 1111,\n",
        "                                         max_depth=30, max_features=6, min_samples_leaf=10)\"\"\"\n",
        "\n",
        "gradient_regressor = GradientBoostingRegressor(n_estimators = 30, random_state =0)\n",
        "gradient_regressor.fit(X_train.reshape(-1, 1), y_train.reshape(-1, 1))\n",
        "\n",
        "\n",
        "X_grid = np.arange(min(X), max(X), 0.01)\n",
        "X_grid = X_grid.reshape(len(X_grid), 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.scatter(X_train, y_train, color='blue', label='Actual observation points')\n",
        "plt.plot(X_grid, gradient_regressor.predict(X_grid), label='Gradient regressor')\n",
        "plt.title('totalRent vs features (Gradient Boosting)')\n",
        "plt.xlabel('features')\n",
        "plt.ylabel('totalRent')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## more models --------------------------------------------------------------------- end of final models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": []
      },
      "source": [
        "#GRADIENT BOOSTING\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "def gradientboostingmachine(md, msl, n, mf, lr, xtrain, ytrain, xtest, ytest):\n",
        "    gbm_best = GradientBoostingRegressor(n_estimators=n, random_state=1111,\n",
        "                                         max_depth=md, max_features=mf, \n",
        "                                         min_samples_leaf=msl, learning_rate=lr\n",
        "                                         )\n",
        "    gbm_best.fit(xtrain, ytrain)\n",
        "    y_pred_gbm = gbm_best.predict(xtest)\n",
        "    print('MAE:', metrics.mean_absolute_error(ytest, y_pred_gbm))\n",
        "    print('MSE:', metrics.mean_squared_error(ytest, y_pred_gbm))\n",
        "    \n",
        "#gradientboostingmachine(16, 117, 73, 10, 0.07, X_train, y_train, X_test, y_test)\n",
        "gradientboostingmachine(16, 117, 157, 5, 0.07, X_train, y_train, X_test, y_test)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": []
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import cross_val_score\n",
        "lin_reg = LinearRegression()\n",
        "\n",
        "\n",
        "scores = cross_val_score(lin_reg, X_train, y_train,\n",
        "                        scoring=\"neg_mean_squared_error\", cv=10)\n",
        "\n",
        "# find root mean squared error, scores is an array of negative numbers\n",
        "rmse_scores = np.sqrt(-scores)\n",
        "\n",
        "print(\"Mean:\\t\\t \", rmse_scores.mean(), \"\\nStandard Deviation:\", rmse_scores.std())\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": []
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
        "\n",
        "y_var = ['logRent']\n",
        "X_var = ['balcony', 'hasKitchen', 'cellar', 'livingSpace', 'noRooms', 'garden', 'baseRent', \n",
        "         'refurbished', 'greatInterior', 'newlyConst',\n",
        "         '2018_ads', 'lift']\n",
        "\n",
        "y = Berlin[y_var].iloc[:,0].values\n",
        "X = Berlin[X_var].iloc[:,3].values\n",
        "\n",
        "#print(X)\n",
        "#print(y)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, \n",
        "                                                    random_state=0)\n",
        "\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_var = ['logRent']\n",
        "X_var = ['balcony', 'hasKitchen', 'cellar', 'livingSpace', 'noRooms', 'garden',\n",
        "         'refurbished', 'greatInterior', 'newlyConst',\n",
        "         '2018_ads', 'lift']\n",
        "\n",
        "y = Berlin[y_var].iloc[:,0].values\n",
        "X = Berlin[X_var].iloc[:,3:4].values\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Simple Vector Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "scale_X = StandardScaler()\n",
        "scale_y = StandardScaler()\n",
        "\n",
        "X = scale_X.fit_transform(X.reshape(-1,1))\n",
        "y = scale_y.fit_transform(y.reshape(-1,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "svr_regressor = SVR(kernel='rbf', gamma='auto')\n",
        "svr_regressor.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.scatter(X, y, color='red', label='Actual observation points')\n",
        "plt.plot(X, svr_regressor.predict(X), label='SVR regressor')\n",
        "plt.title('totalRent vs Ex_features (SVR Regression) ))')\n",
        "plt.xlabel('Ex_features')\n",
        "plt.ylabel('Salary')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Decision Tree - Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "tree_regressor = DecisionTreeRegressor(random_state = 0)\n",
        "tree_regressor.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_grid = np.arange(min(X), max(X), 0.01)\n",
        "X_grid = X_grid.reshape(len(X_grid), 1)\n",
        "\n",
        "plt.scatter(X, y, color='red', label='Actual observation points')\n",
        "plt.plot(X_grid, tree_regressor.predict(X_grid), label='Tree regressor')\n",
        "plt.title('totalRent vs Ex_features (Tree Regression)')\n",
        "plt.xlabel('Ex_features')\n",
        "plt.ylabel('totalRent')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3-final"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}