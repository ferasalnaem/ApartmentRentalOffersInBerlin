{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# To add a new cell, type '# %%'\n",
        "# To add a new markdown cell, type '# %% [markdown]'\n",
        "# %%\n",
        "from IPython import get_ipython\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Python \u22653.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn \u22650.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# To plot pretty figures\n",
        "get_ipython().run_line_magic('matplotlib', 'inline')\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Ignore useless warnings (see SciPy issue #5998)\n",
        "import warnings\n",
        "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing\n",
        "import matplotlib.pyplot as plt # dataviz\n",
        "import seaborn as sns # dataviz\n",
        "from pandas.plotting import scatter_matrix\n",
        "\n",
        "Rental= pd.read_csv(\"./dataset/immo_data.csv\")\n",
        "\n",
        "get_ipython().run_line_magic('matplotlib', 'inline')\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "Rental.describe() #shows a summary of the numerical attributes\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "Berlin=Rental.loc[Rental[\"regio2\"]=='Berlin']\n",
        "print(Berlin)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "corr_matrix = Berlin.corr()\n",
        "corr_matrix[\"totalRent\"].sort_values(ascending=False)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "Berlin.corr()[\"baseRent\"].sort_values(ascending=False)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "Berlin.hist(bins=50, figsize=(15,15))\n",
        "plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "attributes = [\"baseRent\",\"totalRent\",\"livingSpace\", \"serviceCharge\", \"noRooms\",\"heatingCosts\",\"picturecount\"]\n",
        "scatter_matrix(Berlin[attributes], figsize=(16, 12))\n",
        "scatter_matrix\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "Berlin[\"totalRent\"].describe()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.plot(np.log(Berlin[\"totalRent\"]))\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "Berlin['totalRent'].hist(bins=30, range=(100,4000), grid=True, color='#86bf91')\n",
        "plt.title('Distribution of Base Rents')\n",
        "plt.xlabel('Total Rent')\n",
        "plt.ylabel('Count')\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "Berlin.plot(kind=\"scatter\", x=\"livingSpace\", y=\"baseRent\", alpha=0.1)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "m=Berlin.groupby(['regio3'])['baseRent'].mean()\n",
        "m.sort_values()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#droping initial columns\n",
        "cols_to_drop = [\"telekomHybridUploadSpeed\", \"picturecount\", \"telekomUploadSpeed\",\n",
        "                \"geo_bln\", \"houseNumber\", \"geo_krs\", \"geo_plz\", \"regio3\", \"description\",\n",
        "                \"facilities\"]\n",
        "\n",
        "Berlin = Berlin.drop(cols_to_drop, axis=1)\n",
        "\n",
        "#Columns with several NULL entries are dropped too.\n",
        "\n",
        "Berlin.isna().sum()\n",
        "\n",
        "#filter columns for berlin\n",
        "Berlin = Berlin[Berlin[\"regio2\"]==\"Berlin\"]\n",
        "\n",
        "#sorting and re_indexing regarding to the price\n",
        "Berlin = Berlin.sort_values(by=['totalRent'])\n",
        "Berlin = Berlin.reset_index(drop=True)\n",
        "\n",
        "#filter some columns between specific amount of values\n",
        "Berlin = Berlin.query(\"totalRent >= 100\").query(\"totalRent<10000\")\n",
        "Berlin = Berlin.query(\"baseRent >= 100\").query(\"baseRent<10000\")\n",
        "Berlin = Berlin.query(\"livingSpace >= 10\").query(\"livingSpace<400\")\n",
        "Berlin = Berlin.query(\"noRooms >= 0\").query(\"noRooms<15\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Replacing columns with f/t with 0/1\n",
        "Berlin.replace({False: 0, True: 1}, inplace=True)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#make a single binary variable to indicate if the apartment is refurbished/new\n",
        "Berlin['refurbished'] = (Berlin.condition == 'refurbished') | (Berlin.condition == 'first_time_use') | (Berlin.condition == 'mint_condition') | (Berlin.condition == 'fully_renovated') | (Berlin.condition == 'first_time_use_after_refurbishment')\n",
        "\n",
        "#make a binary variable to indicate if the rental property has good interior\n",
        "Berlin['greatInterior'] = (Berlin.interiorQual == 'sophisticated') | (Berlin.interiorQual == 'luxury')\n",
        "\n",
        "#make a binary variable to indicated if the rental property has good heating\n",
        "Berlin['goodHeating'] = (Berlin.heatingType == 'central_heating') | (Berlin.heatingType == 'floor_heating') | (Berlin.heatingType == 'self_contained_central_heating')\n",
        "\n",
        "#make a binary variable to identify rental ads from last year to factor in any inflationary effects.\n",
        "Berlin['2018_ads'] = (Berlin.date == 'Sep18')\n",
        "\n",
        "#transform totalRent into log(totalRent) to get a better distribution + better interpretive quality\n",
        "Berlin['logRent'] = np.log(Berlin['totalRent'])\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y_var = ['logRent']\n",
        "X_var = ['balcony', 'hasKitchen', 'cellar', 'livingSpace', 'noRooms', 'garden',\n",
        "         'refurbished', 'greatInterior', 'newlyConst',\n",
        "         '2018_ads', 'lift']\n",
        "\n",
        "\n",
        "#Berlin[X_var].replace({False: 0, True: 1}, inplace=True)\n",
        "y = Berlin[y_var].values\n",
        "X = Berlin[X_var].values\n",
        "\n",
        "#print(X)\n",
        "#print(y)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, \n",
        "                                                    random_state=42)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#LINEAR REGRESSION\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import metrics\n",
        "\n",
        "def linearregression(xtrain, ytrain, xtest, ytest):\n",
        "    linreg = LinearRegression()\n",
        "    linreg.fit(xtrain, ytrain)\n",
        "    y_pred = linreg.predict(xtest)\n",
        "    print('MAE:', metrics.mean_absolute_error(ytest, y_pred))\n",
        "    print('MSE:', metrics.mean_squared_error(ytest, y_pred))\n",
        "\n",
        "linearregression(X_train, y_train, X_test, y_test)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "#RANDOM FOREST\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "#Best hyperparamters from the Random Search:\n",
        "#minsamleaf: 30, maxfeat: 11, maxdepth: 24 \n",
        "\n",
        "def randomforestreg(msl, mf, md, xtrain, ytrain, xtest, ytest):\n",
        "    rfr_best = RandomForestRegressor(n_estimators=70, random_state=1111,\n",
        "                                     max_depth=md, max_features=mf, min_samples_leaf=msl)\n",
        "    rfr_best.fit(xtrain,ytrain)\n",
        "    y_pred_rfr = rfr_best.predict(xtest)\n",
        "    print('MAE:', metrics.mean_absolute_error(ytest, y_pred_rfr))\n",
        "    print('MSE:', metrics.mean_squared_error(ytest, y_pred_rfr))\n",
        "    \n",
        "randomforestreg(30, 11, 24, X_train, y_train, X_test, y_test)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#GRADIENT BOOSTING\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "#Best hyperparameters from Random Search:\n",
        "#maxdepth: 16, minsamleaf: 117, n: 73, maxfeat: 10, lr: 0.07\n",
        "def gradientboostingmachine(md, msl, n, mf, lr, xtrain, ytrain, xtest, ytest):\n",
        "    gbm_best = GradientBoostingRegressor(n_estimators=n, random_state=1111,\n",
        "                                         max_depth=md, max_features=mf, \n",
        "                                         min_samples_leaf=msl, learning_rate=lr\n",
        "                                         )\n",
        "    gbm_best.fit(xtrain, ytrain)\n",
        "    y_pred_gbm = gbm_best.predict(xtest)\n",
        "    print('MAE:', metrics.mean_absolute_error(ytest, y_pred_gbm))\n",
        "    print('MSE:', metrics.mean_squared_error(ytest, y_pred_gbm))\n",
        "    \n",
        "gradientboostingmachine(16, 117, 73, 10, 0.07, X_train, y_train, X_test, y_test)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import cross_val_score\n",
        "lin_reg = LinearRegression()\n",
        "\n",
        "\n",
        "scores = cross_val_score(lin_reg, X_train, y_train,\n",
        "                        scoring=\"neg_mean_squared_error\", cv=10)\n",
        "\n",
        "# find root mean squared error, scores is an array of negative numbers\n",
        "rmse_scores = np.sqrt(-scores)\n",
        "\n",
        "print(\"Mean:\\t\\t \", rmse_scores.mean(), \"\\nStandard Deviation:\", rmse_scores.std())\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "forest_reg = RandomForestRegressor()\n",
        "forest_reg.fit(X_train, y_train)\n",
        "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
        "           max_features='auto', max_leaf_nodes=None,\n",
        "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "           min_samples_leaf=1, min_samples_split=2,\n",
        "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
        "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
        "forest_scores = cross_val_score(forest_reg, X_train, y_train,\n",
        "                               scoring=\"neg_mean_squared_error\", cv=10)\n",
        "forest_rmse_scores = np.sqrt(-forest_scores)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Mean:\\t\\t \", forest_rmse_scores.mean(), \"\\nStandard Deviation:\", forest_rmse_scores.std())\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def stackedmodel(xtrain, ytrain, xtest, ytest):\n",
        "    x_training, x_valid, y_training, y_valid = train_test_split(xtrain, ytrain,\n",
        "                                                                test_size=0.5,\n",
        "                                                                random_state=42)\n",
        "    model1 = LinearRegression()\n",
        "    model2 = RandomForestRegressor(n_estimators=70, random_state=1111,\n",
        "                                   max_depth=24, max_features=11, \n",
        "                                   min_samples_leaf=24)\n",
        "    model3 = GradientBoostingRegressor(n_estimators=73, random_state=1111,\n",
        "                                       max_depth=16, max_features=10, \n",
        "                                       min_samples_leaf=117, learning_rate=0.07)\n",
        "    \n",
        "    model1.fit(x_training, y_training)\n",
        "    model2.fit(x_training, y_training)\n",
        "    model3.fit(x_training, y_training)\n",
        "    \n",
        "    preds1 = model1.predict(x_valid)\n",
        "    preds2 = model2.predict(x_valid)\n",
        "    preds3 = model3.predict(x_valid)\n",
        "    \n",
        "    testpreds1 = model1.predict(xtest)\n",
        "    testpreds2 = model2.predict(xtest)\n",
        "    testpreds3 = model3.predict(xtest)\n",
        "    \n",
        "    stackedpredictions = np.column_stack((preds1, preds2, preds3))\n",
        "    stackedtestpredictions = np.column_stack((testpreds1, testpreds2,\n",
        "                                              testpreds3))\n",
        "    \n",
        "    metamodel = LinearRegression()\n",
        "    metamodel.fit(stackedpredictions, y_valid)\n",
        "    final_predictions = metamodel.predict(stackedtestpredictions)\n",
        "    print('MAE:', metrics.mean_absolute_error(ytest, final_predictions))\n",
        "    print('MSE:', metrics.mean_squared_error(ytest, final_predictions))\n",
        "\n",
        "stackedmodel(X_train, y_train, X_test, y_test)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}